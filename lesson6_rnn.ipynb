{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson6-rnn.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ryuwryyy/fastai_colab/blob/master/lesson6_rnn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "cyFxQCb-3NFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2791
        },
        "outputId": "8bffa48e-68e8-45ab-9381-5777cb6b036d"
      },
      "cell_type": "code",
      "source": [
        "# %reload_ext autoreload\n",
        "# %autoreload 2\n",
        "# %matplotlib inline\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "!pip install torchtext\n",
        "\n",
        "!pip install bcolz\n",
        "!pip install graphviz\n",
        "!pip install sklearn_pandas\n",
        "!pip install isoweek\n",
        "!pip install pandas_summary\n",
        "!pip install ipywidgets\n",
        "!pip install fastai\n",
        "\n",
        "from fastai.imports import *"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpjmo30223/pubring.gpg' created\n",
            "gpg: /tmp/tmpjmo30223/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "Requirement already satisfied: torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0.post4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.12)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.12)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.23.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.18.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2018.4.16)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: bcolz in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.14.3)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.8.3)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: sklearn_pandas in /usr/local/lib/python3.6/dist-packages (1.6.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from sklearn_pandas) (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from sklearn_pandas) (1.14.3)\n",
            "Requirement already satisfied: scikit-learn>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_pandas) (0.19.1)\n",
            "Requirement already satisfied: pandas>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_pandas) (0.22.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.11.0->sklearn_pandas) (2018.4)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.11.0->sklearn_pandas) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas>=0.11.0->sklearn_pandas) (1.11.0)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: isoweek in /usr/local/lib/python3.6/dist-packages (1.3.3)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: pandas_summary in /usr/local/lib/python3.6/dist-packages (0.0.41)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pandas_summary) (1.14.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pandas_summary) (0.22.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->pandas_summary) (2018.4)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->pandas_summary) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas->pandas_summary) (1.11.0)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (7.2.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (3.2.1)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.4.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.6.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.3.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.2.0->ipywidgets) (5.2.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.3.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (39.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (1.0.15)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.2.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets) (1.11.0)\r\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets) (0.8.1)\r\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets) (2.10)\r\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets) (5.3.1)\r\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.5.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (16.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets) (1.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: mistune>=0.7.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets) (0.3.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets) (0.2.3)\n",
            "Requirement already satisfied: html5lib!=0.9999,!=0.99999,<0.99999999,>=0.999 in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets) (0.9999999)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from fastai) (2.6.0)\n",
            "Requirement already satisfied: feather-format in /usr/local/lib/python3.6/dist-packages (from fastai) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from fastai) (3.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fastai) (4.23.4)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from fastai) (16.0.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from fastai) (4.3.0)\n",
            "Requirement already satisfied: isoweek in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (5.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.14.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.6/dist-packages (from fastai) (0.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from fastai) (1.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from fastai) (2018.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from fastai) (0.5.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from fastai) (7.2.1)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.6/dist-packages (from fastai) (0.3.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from fastai) (4.5.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from fastai) (0.1.7)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from fastai) (0.9999999)\n",
            "Requirement already satisfied: pandas-summary in /usr/local/lib/python3.6/dist-packages (from fastai) (0.0.41)\n",
            "Requirement already satisfied: bcolz in /usr/local/lib/python3.6/dist-packages (from fastai) (1.2.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from fastai) (0.8.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.0)\n",
            "Requirement already satisfied: torch<0.4 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.3.0.post4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.1)\n",
            "Requirement already satisfied: jedi in /usr/local/lib/python3.6/dist-packages (from fastai) (0.12.0)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.10)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from fastai) (2.5.3)\n",
            "Requirement already satisfied: sklearn-pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (1.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from fastai) (2018.4.16)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from fastai) (0.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.1)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from fastai) (0.10.0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from fastai) (4.3.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from fastai) (3.4.1.15)\n",
            "Requirement already satisfied: simplegeneric in /usr/local/lib/python3.6/dist-packages (from fastai) (0.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (0.19.1)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from fastai) (5.5.0)\n",
            "Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from feather-format->fastai) (0.9.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai) (4.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai) (5.2.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai) (5.3.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->fastai) (2.18.4)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->fastai) (4.4.0)\n",
            "Requirement already satisfied: mizani>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai) (0.4.6)\n",
            "Requirement already satisfied: statsmodels>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai) (0.8.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai) (0.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->fastai) (5.2.3)\n",
            "Requirement already satisfied: parso>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from jedi->fastai) (0.2.1)\n",
            "Requirement already satisfied: scikit-learn>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-pandas->fastai) (0.19.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai) (1.0.15)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai) (39.2.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->fastai) (4.5.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->fastai) (4.4.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->fastai) (0.8.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.7.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai) (0.8.3)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai) (2.6)\n",
            "Requirement already satisfied: palettable in /usr/local/lib/python3.6/dist-packages (from mizani>=0.4.1->plotnine->fastai) (3.1.1)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XI4k2vX3hjMj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.io import *\n",
        "from fastai.conv_learner import *\n",
        "\n",
        "from fastai.column_data import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YVPOHgYj-LXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0a480991-06f0-4fc0-d81d-950d9cfe58c2"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iS9PhmaJoro7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "arYLe4xnhjMo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "DLcEhVU0hjMq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're going to download the collected works of Nietzsche to use as our data for this class."
      ]
    },
    {
      "metadata": {
        "id": "1RhipWi74_GY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9990c18d-804d-4d13-cfb2-b930fda64c75"
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd drive \n",
        "cd fastai\n",
        "cd courses\n",
        "cd dl1\n",
        "cd data\n",
        "pwd"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/fastai/courses/dl1/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4wet0HxRhjMr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH='/content/drive/fastai/courses/dl1/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VyNv4RkuhjMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7a0b0d9-657f-47bf-8ca8-4f8d05ae8319"
      },
      "cell_type": "code",
      "source": [
        "# get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
        "text = open(f'{PATH}nietzsche.txt').read()\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 611277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HF_UouNEhjM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "240c31c1-88ef-4e44-81fb-70aa8f7bd330"
      },
      "cell_type": "code",
      "source": [
        "text[:400]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\\\rtf1\\\\ansi\\\\ansicpg932\\\\cocoartf1504\\\\cocoasubrtf830\\n{\\\\fonttbl\\\\f0\\\\fmodern\\\\fcharset0 Courier;}\\n{\\\\colortbl;\\\\red255\\\\green255\\\\blue255;\\\\red0\\\\green0\\\\blue0;}\\n{\\\\*\\\\expandedcolortbl;;\\\\cssrgb\\\\c0\\\\c0\\\\c0;}\\n\\\\paperw11900\\\\paperh16840\\\\margl1440\\\\margr1440\\\\vieww10800\\\\viewh8400\\\\viewkind0\\n\\\\deftab720\\n\\\\pard\\\\pardeftab720\\\\sl280\\\\partightenfactor0\\n\\n\\\\f0\\\\fs24 \\\\cf2 \\\\expnd0\\\\expndtw0\\\\kerning0\\n\\\\outl0\\\\strokewidth0 \\\\strokec2 PREFACE\\\\\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "9MRnyEE-hjM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b764f86-a67e-4098-ee9f-edf61ae721bb"
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)+1\n",
        "print('total chars:', vocab_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dm4qdsIdhjNC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sometimes it's useful to have a zero value in the dataset, e.g. for padding"
      ]
    },
    {
      "metadata": {
        "id": "_p-MJXwqhjNE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "778a60d4-89df-4e76-e3c0-a6660ed2b249"
      },
      "cell_type": "code",
      "source": [
        "chars.insert(0, \"\\0\")\n",
        "\n",
        "''.join(chars[1:-6])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n !\"\\'()*,-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]_abcdefghijklmnopqrstuv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "LlN6wtjDhjNK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Map from chars to indices and back again"
      ]
    },
    {
      "metadata": {
        "id": "J5ZdF_J_hjNM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char_indices = {c: i for i, c in enumerate(chars)}\n",
        "indices_char = {i: c for i, c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W0T6KUExhjNQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*idx* will be the data we use from now own - it simply converts all the characters to their index (based on the mapping above)"
      ]
    },
    {
      "metadata": {
        "id": "cnfFMbs9hjNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56b74ffd-5974-49b0-c2a8-c10e1f5d0ad3"
      },
      "cell_type": "code",
      "source": [
        "idx = [char_indices[c] for c in text]\n",
        "\n",
        "idx[:10]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[82, 53, 73, 75, 61, 13, 53, 56, 69, 74]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "FIiYoh1KhjNV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "13f5dd78-2f70-4a47-f9ac-088a89480b73"
      },
      "cell_type": "code",
      "source": [
        "''.join(indices_char[i] for i in idx[:70])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\\\rtf1\\\\ansi\\\\ansicpg932\\\\cocoartf1504\\\\cocoasubrtf830\\n{\\\\fonttbl\\\\f0\\\\fmoder'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "R1JEWIgshjNe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Three char model"
      ]
    },
    {
      "metadata": {
        "id": "iKbvP1CJhjNf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create inputs"
      ]
    },
    {
      "metadata": {
        "id": "ReuYw5guhjNg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters"
      ]
    },
    {
      "metadata": {
        "id": "f6jMNMdDhjNi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cs=3\n",
        "c1_dat = [idx[i]   for i in range(0, len(idx)-cs, cs)]\n",
        "c2_dat = [idx[i+1] for i in range(0, len(idx)-cs, cs)]\n",
        "c3_dat = [idx[i+2] for i in range(0, len(idx)-cs, cs)]\n",
        "c4_dat = [idx[i+3] for i in range(0, len(idx)-cs, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4ufBNivhjNm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our inputs"
      ]
    },
    {
      "metadata": {
        "id": "CXbkMg6yhjNm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1 = np.stack(c1_dat)\n",
        "x2 = np.stack(c2_dat)\n",
        "x3 = np.stack(c3_dat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2_R0iv0HhjNs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our output"
      ]
    },
    {
      "metadata": {
        "id": "Mrj3xbAmhjNt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = np.stack(c4_dat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7dcOc7aBhjNy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first 4 inputs and outputs"
      ]
    },
    {
      "metadata": {
        "id": "FXSh0H92hjNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3624a44f-89ee-4709-feb2-9336aa0dbf79"
      },
      "cell_type": "code",
      "source": [
        "x1[:4], x2[:4], x3[:4]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([82, 75, 53, 74]), array([53, 61, 56, 64]), array([73, 13, 69, 53]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "lSIEAodzhjN4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51710fc8-91f8-4c30-9136-ca99540b293b"
      },
      "cell_type": "code",
      "source": [
        "y[:4]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([75, 53, 74, 56])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "U62Xy7G6hjN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7912037d-7038-4f6c-a60b-86acb680082d"
      },
      "cell_type": "code",
      "source": [
        "x1.shape, y.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((203758,), (203758,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "9y-ChuNYhjOC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create and train model"
      ]
    },
    {
      "metadata": {
        "id": "mcgwGfyWhjOD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pick a size for our hidden state"
      ]
    },
    {
      "metadata": {
        "id": "VVJptPxIhjOD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_hidden = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lLzSJrvHhjOK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The number of latent factors to create (i.e. the size of the embedding matrix)"
      ]
    },
    {
      "metadata": {
        "id": "K5YMjYt0hjOL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_fac = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JgYHcFXAhjOQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Char3Model(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "\n",
        "        # The 'green arrow' from our diagram - the layer operation from input to hidden\n",
        "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
        "\n",
        "        # The 'orange arrow' from our diagram - the layer operation from hidden to hidden\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        \n",
        "        # The 'blue arrow' from our diagram - the layer operation from hidden to output\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, c1, c2, c3):\n",
        "        in1 = F.relu(self.l_in(self.e(c1)))\n",
        "        in2 = F.relu(self.l_in(self.e(c2)))\n",
        "        in3 = F.relu(self.l_in(self.e(c3)))\n",
        "        \n",
        "        h = V(torch.zeros(in1.size()).cuda())\n",
        "        h = F.tanh(self.l_hidden(h+in1))\n",
        "        h = F.tanh(self.l_hidden(h+in2))\n",
        "        h = F.tanh(self.l_hidden(h+in3))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gfarpQIIhjOV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P0vR9VqmhjOY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = Char3Model(vocab_size, n_fac).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7R7IBEw8hjOd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)\n",
        "t = m(*V(xs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bIoHXySrhjOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(m.parameters(), 1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LoyhBLT1hjOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b96e9e2c-48da-468b-f46f-4ad6d704d94a"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "376219632ee64bdd904a6ad253c81b71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      2.028914   1.400064  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.40006])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "HKG4AbBmhjOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8OcnN7ChhjOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f6752a78-a77b-43d6-9261-a16d48ecd693"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e55e5398e4474697905e414997d84094",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.783591   1.838515  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.83851])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "7TGJIK3yhjOv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ]
    },
    {
      "metadata": {
        "id": "sf50dYXVhjOw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
        "    p = m(*VV(idxs))\n",
        "    i = np.argmax(to_np(p))\n",
        "    return chars[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hKLLvSb0hjO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fddba89e-5354-4c60-905a-9201f17931f9"
      },
      "cell_type": "code",
      "source": [
        "get_next('y. ')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "BMNZcbWehjO4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f8b753e-5284-4411-d2f5-9e6b98194b11"
      },
      "cell_type": "code",
      "source": [
        "get_next('ppl')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "E5P1skOChjO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dbad88b-6885-465d-e6e3-b6c48b76cd7d"
      },
      "cell_type": "code",
      "source": [
        "get_next(' th')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "INT4W6TShjO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "421a881c-0bd4-404e-8a77-02bf58e038e4"
      },
      "cell_type": "code",
      "source": [
        "get_next('and')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "tA0qXYRKhjPC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Our first RNN!"
      ]
    },
    {
      "metadata": {
        "id": "cB2-DvTIhjPD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create inputs"
      ]
    },
    {
      "metadata": {
        "id": "8kwhKDxThjPD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the size of our unrolled RNN."
      ]
    },
    {
      "metadata": {
        "id": "vesRVFzOhjPE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cs=8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7PqRYYk0hjPI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to out model."
      ]
    },
    {
      "metadata": {
        "id": "JikglwQBhjPK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(len(idx)-cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LdVkjtPshjPM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then create a list of the next character in each of these series. This will be the labels for our model."
      ]
    },
    {
      "metadata": {
        "id": "rL41tzB_hjPT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_out_dat = [idx[j+cs] for j in range(len(idx)-cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XRNtSIBUhjPU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs = np.stack(c_in_dat, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y5YaxcKnhjPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c779687d-6b13-4c04-d1ee-6287e976ef57"
      },
      "cell_type": "code",
      "source": [
        "xs.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(611269, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "Bj_ci3Z3hjPe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = np.stack(c_out_dat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FqDzX227hjPh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So each column below is one series of 8 characters from the text."
      ]
    },
    {
      "metadata": {
        "id": "c1mizMMUhjPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "8456e63f-7b6d-4c1a-da9c-d2a00feca415"
      },
      "cell_type": "code",
      "source": [
        "xs[:cs,:cs]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[82, 53, 73, 75, 61, 13, 53, 56],\n",
              "       [53, 73, 75, 61, 13, 53, 56, 69],\n",
              "       [73, 75, 61, 13, 53, 56, 69, 74],\n",
              "       [75, 61, 13, 53, 56, 69, 74, 64],\n",
              "       [61, 13, 53, 56, 69, 74, 64, 53],\n",
              "       [13, 53, 56, 69, 74, 64, 53, 56],\n",
              "       [53, 56, 69, 74, 64, 53, 56, 69],\n",
              "       [56, 69, 74, 64, 53, 56, 69, 74]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "Ac3ctxN2hjPo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "...and this is the next character after each sequence."
      ]
    },
    {
      "metadata": {
        "id": "baS4T7erhjPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1e7bb6a-36d6-44eb-c2cc-15d48ee9eca9"
      },
      "cell_type": "code",
      "source": [
        "y[:cs]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([69, 74, 64, 53, 56, 69, 74, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "4SjWY2bThjPu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create and train model"
      ]
    },
    {
      "metadata": {
        "id": "ny_PrgP3hjPv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_idx = get_cv_idxs(len(idx)-cs-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FO_CqLw4hjPy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QhCr8xVRhjP2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharLoopModel(nn.Module):\n",
        "    # This is an RNN!\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
        "        for c in cs:\n",
        "            inp = F.relu(self.l_in(self.e(c)))\n",
        "            h = F.tanh(self.l_hidden(h+inp))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JDdQNxvphjP3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharLoopModel(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wTIjcyzFhjP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "229dc82a-60d6-4ef1-9930-00e3617ce2c9"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cba4bc4119542a9988211d4ade03453",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.995524   2.054674  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([2.05467])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "yU5EkrqWhjQB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d6Mb__TrhjQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "381d5d29-068c-4a85-94ab-aa6bfedd6223"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7190f032f4bc44c3b81c5feb68312263",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.721706   1.719721  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.71972])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "YKP7Q4-thjQH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharLoopConcatModel(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.l_in = nn.Linear(n_fac+n_hidden, n_hidden)\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
        "        for c in cs:\n",
        "            inp = torch.cat((h, self.e(c)), 1)\n",
        "            inp = F.relu(self.l_in(inp))\n",
        "            h = F.tanh(self.l_hidden(inp))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6lXynuKEhjQK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharLoopConcatModel(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0vvsaXq4hjQO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)\n",
        "t = m(*V(xs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYvSgkXWhjQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8846857c-d7bf-4444-8f4f-c5979e987b46"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f3accc0e1ea47f18efbb17fc92c93d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.85556    1.834462  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.83446])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "iACEpyXzhjQd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FUA1Kkc0hjQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "46e38a1e-9008-4ff7-c1bd-c8667268f827"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19603703262c4413b2c7042e771b4cd6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.751862   1.748123  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.74812])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "d9QK7s0JhjQn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ]
    },
    {
      "metadata": {
        "id": "NiKhguqXhjQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
        "    p = m(*VV(idxs))\n",
        "    i = np.argmax(to_np(p))\n",
        "    return chars[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8WeAGN_SqUj1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KXOLuxwvhjQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8aa08e4-7998-4fb9-d770-a3f4a5f4b540"
      },
      "cell_type": "code",
      "source": [
        "get_next('for thos')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'_'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "YfzSWMFphjQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b8cfb8b-95e0-4804-b4b6-1c3cb4d05e68"
      },
      "cell_type": "code",
      "source": [
        "get_next('part of ')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Y'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "JzlNN_0NhjQz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64ac4e96-0821-4b87-f00b-cd83d2a571b5"
      },
      "cell_type": "code",
      "source": [
        "get_next('queens a')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "CprhqeK3hjQ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## RNN with pytorch"
      ]
    },
    {
      "metadata": {
        "id": "m43CAekuhjQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharRnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(1, bs, n_hidden))\n",
        "        inp = self.e(torch.stack(cs))\n",
        "        outp,h = self.rnn(inp, h)\n",
        "        \n",
        "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1L-St_2qhjQ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharRnn(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FFli3PolhjQ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "69V_3AmIhjQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60f3d6af-50e8-4d2a-f1b5-ec1e5d4f75fe"
      },
      "cell_type": "code",
      "source": [
        "t = m.e(V(torch.stack(xs)))\n",
        "t.size()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 512, 42])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "pX8sQOmGhjRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d67c6075-6d5b-4248-f60c-f9135dce35cc"
      },
      "cell_type": "code",
      "source": [
        "ht = V(torch.zeros(1, 512,n_hidden))\n",
        "outp, hn = m.rnn(t, ht)\n",
        "outp.size(), hn.size()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 512, 256]), torch.Size([1, 512, 256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "R6Nr28zehjRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f91f95a5-2613-4688-ab72-acf2e3056d4e"
      },
      "cell_type": "code",
      "source": [
        "t = m(*V(xs)); t.size()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 84])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "i9hphzEzhjRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "52ef8300-b549-491c-f26e-9018f0dd82ed"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8d3dbcaf5dd4b66b858990b491949d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.819595   1.811873  \n",
            " 21%|██▏       | 205/956 [00:06<00:24, 30.64it/s, loss=1.76]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.649484   1.650412  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.555515   1.579529  \n",
            "    3      1.518035   1.535175  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.53517])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "i0p4FNFwhjRN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nHtnoTwnhjRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2a9570c8-6c9a-45c1-b494-9e1cfe16f552"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 2, opt, F.nll_loss)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2efc9e4247a64d0d9fbb526bb60f7014",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.451645   1.494163  \n",
            " 21%|██        | 201/956 [00:07<00:26, 28.56it/s, loss=1.44]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.445542   1.489428  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.48943])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "hfeKr71YhjRR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ]
    },
    {
      "metadata": {
        "id": "QSlFDX2nhjRR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
        "    p = m(*VV(idxs))\n",
        "    i = np.argmax(to_np(p))\n",
        "    return chars[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l-0d3CMqhjRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0df5b11-182f-4fbe-a449-ad75d44ce82c"
      },
      "cell_type": "code",
      "source": [
        "get_next('for thos')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "Dhq-cfwghjRU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next_n(inp, n):\n",
        "    res = inp\n",
        "    for i in range(n):\n",
        "        c = get_next(inp)\n",
        "        res += c\n",
        "        inp = inp[1:]+c\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LoEQKQH-hjRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb6229c3-11e8-4c58-f393-db0690e1e7d7"
      },
      "cell_type": "code",
      "source": [
        "get_next_n('for thos', 40)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for thos{_E 1xYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "SFZOkDLehjRY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multi-output model"
      ]
    },
    {
      "metadata": {
        "id": "UpWGb-vxhjRb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ]
    },
    {
      "metadata": {
        "id": "rbK3XDfWhjRb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's take non-overlapping sets of characters this time"
      ]
    },
    {
      "metadata": {
        "id": "7iOoN9Z6hjRd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(0, len(idx)-cs-1, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "laxMunJYhjRi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then create the exact same thing, offset by 1, as our labels"
      ]
    },
    {
      "metadata": {
        "id": "f5f5Ai3BhjRj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_out_dat = [[idx[i+j] for i in range(cs)] for j in range(1, len(idx)-cs, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J_Wpz3Z0hjRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31b38c9f-f6d6-437e-9e46-84a5503793c2"
      },
      "cell_type": "code",
      "source": [
        "xs = np.stack(c_in_dat)\n",
        "xs.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76409, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "MhK1H_QJhjRp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10402256-7688-4554-cc7b-9645512c2532"
      },
      "cell_type": "code",
      "source": [
        "ys = np.stack(c_out_dat)\n",
        "ys.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76409, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "N7Sw1R29hjRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "afc63073-040c-4463-ff24-4dcb6593bc4e"
      },
      "cell_type": "code",
      "source": [
        "xs[:cs,:cs]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[82, 53, 73, 75, 61, 13, 53, 56],\n",
              "       [69, 74, 64, 53, 56, 69, 74, 64],\n",
              "       [58, 71, 62, 21, 15, 14, 53, 58],\n",
              "       [70, 58, 70, 56, 73, 75, 61, 13],\n",
              "       [17, 12, 16, 53, 58, 70, 58, 70],\n",
              "       [56, 74, 76, 57, 73, 75, 61, 20],\n",
              "       [15, 12,  1, 82, 53, 61, 70, 69],\n",
              "       [75, 75, 57, 67, 53, 61, 12, 53]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "EHQ-rQdZhjRs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "50b87356-e2ab-487d-b7e9-87598a386fe8"
      },
      "cell_type": "code",
      "source": [
        "ys[:cs,:cs]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[53, 73, 75, 61, 13, 53, 56, 69],\n",
              "       [74, 64, 53, 56, 69, 74, 64, 58],\n",
              "       [71, 62, 21, 15, 14, 53, 58, 70],\n",
              "       [58, 70, 56, 73, 75, 61, 13, 17],\n",
              "       [12, 16, 53, 58, 70, 58, 70, 56],\n",
              "       [74, 76, 57, 73, 75, 61, 20, 15],\n",
              "       [12,  1, 82, 53, 61, 70, 69, 75],\n",
              "       [75, 57, 67, 53, 61, 12, 53, 61]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "AMcXqQzVhjRu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create and train model"
      ]
    },
    {
      "metadata": {
        "id": "J04_2mSAhjRu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_idx = get_cv_idxs(len(xs)-cs-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xUq5pERUhjRy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xe4iAnxbhjR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqRnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(1, bs, n_hidden))\n",
        "        inp = self.e(torch.stack(cs))\n",
        "        outp,h = self.rnn(inp, h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wee3H7_rhjR5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y0DqijZFhjR7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xst,yt = next(it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-2Ny4VqhjR8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def nll_loss_seq(inp, targ):\n",
        "    sl,bs,nh = inp.size()\n",
        "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
        "    return F.nll_loss(inp.view(-1,nh), targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BnLe0_WhhjR-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c38e70da-1db5-4c99-f58f-326547730854"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, nll_loss_seq)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d7faa5c7bef4706856f25d584276cf2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      2.559035   2.361934  \n",
            "    1      2.253459   2.162219  \n",
            "    2      2.102857   2.049953  \n",
            "    3      2.01354    1.979157  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.97916])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "metadata": {
        "id": "y-p8Vu35hjR_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NfwmqvrIhjSC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0bb05d6c-d8d4-423f-db63-1f44165b1666"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, nll_loss_seq)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa6c4f606e98455a82ab34133a404634",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.965606   1.964351  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.96435])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {
        "id": "DOED4Jd4hjSF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Identity init!"
      ]
    },
    {
      "metadata": {
        "id": "ssvn-DsshjSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rxjl_XeRhjSG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "cadab442-f3ee-408e-e90f-9094cacd203b"
      },
      "cell_type": "code",
      "source": [
        "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    1     0     0  ...      0     0     0\n",
              "    0     1     0  ...      0     0     0\n",
              "    0     0     1  ...      0     0     0\n",
              "       ...          ⋱          ...       \n",
              "    0     0     0  ...      1     0     0\n",
              "    0     0     0  ...      0     1     0\n",
              "    0     0     0  ...      0     0     1\n",
              "[torch.cuda.FloatTensor of size 256x256 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "mbtQiXnChjSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e2420655-5346-43ec-8a90-b44a78ff279b"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, nll_loss_seq)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06fa4310fee046b3837c00e48053ff8f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      2.299149   2.127625  \n",
            "    1      2.03591    1.979326  \n",
            "    2      1.933386   1.902763  \n",
            "    3      1.883065   1.874069  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.87407])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "metadata": {
        "id": "0SKuZRwshjSK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cjr5aISlhjSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8ac51a06-d936-4493-b5a0-38a2443275ef"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, nll_loss_seq)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ad50e9dc592483d8ca91ed1e7c7de11",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.790459   1.804721  \n",
            "    1      1.776234   1.7974    \n",
            "    2      1.766276   1.79309   \n",
            "    3      1.758587   1.787752  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.78775])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "YT5iB68UhjSM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stateful model"
      ]
    },
    {
      "metadata": {
        "id": "oYeko175hjSM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ]
    },
    {
      "metadata": {
        "id": "OkGRex9nGmBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        },
        "outputId": "1209c43d-fc23-453a-dd90-1fbfc02c68f8"
      },
      "cell_type": "code",
      "source": [
        "!pip install spacy \n",
        "from torchtext import vocab, data\n",
        "\n",
        "from fastai.nlp import *\n",
        "from fastai.lm_rnn import *"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/31/e60f88751e48851b002f78a35221d12300783d5a43d4ef12fbf10cca96c3/spacy-2.0.11.tar.gz (17.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.6MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.14.3)\n",
            "Collecting murmurhash<0.29,>=0.28 (from spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/31/c8c1ecafa44db30579c8c457ac7a0f819e8b1dbc3e58308394fff5ff9ba7/murmurhash-0.28.0.tar.gz\n",
            "Collecting cymem<1.32,>=1.30 (from spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/9e/273fbea507de99166c11cd0cb3fde1ac01b5bc724d9a407a2f927ede91a1/cymem-1.31.2.tar.gz\n",
            "Collecting preshed<2.0.0,>=1.0.0 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/ac/7c17b1fd54b60972785b646d37da2826311cca70842c011c4ff84fbe95e0/preshed-1.0.0.tar.gz (89kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 14.4MB/s \n",
            "\u001b[?25hCollecting thinc<6.11.0,>=6.10.1 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/fd/e9f36081e6f53699943381858848f3b4d759e0dd03c43b98807dde34c252/thinc-6.10.2.tar.gz (1.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.2MB 12.2MB/s \n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6 (from spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Collecting pathlib (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/9b065a76b9af472437a0059f77e8f962fe350438b927cb80184c32f075eb/pathlib-1.0.1.tar.gz (49kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 18.8MB/s \n",
            "\u001b[?25hCollecting ujson>=1.35 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
            "\u001b[K    100% |████████████████████████████████| 194kB 23.2MB/s \n",
            "\u001b[?25hCollecting dill<0.3,>=0.2 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/a0/19d4d31dee064fc553ae01263b5c55e7fb93daff03a69debbedee647c5a0/dill-0.2.7.1.tar.gz (64kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 22.4MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K    100% |████████████████████████████████| 604kB 18.6MB/s \n",
            "\u001b[?25hCollecting wrapt (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/47/66897906448185fcb77fc3c2b1bc20ed0ecca81a0f2f88eda3fc5a34fc3d/wrapt-1.10.11.tar.gz\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (4.23.4)\n",
            "Collecting cytoolz<0.9,>=0.8 (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/e6/ccc124714dcc1bd511e64ddafb4d5d20ada2533b92e3173a4cf09e0d0831/cytoolz-0.8.2.tar.gz (386kB)\n",
            "\u001b[K    100% |████████████████████████████████| 389kB 22.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.11.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.1.0)\n",
            "Collecting msgpack-python (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/20/6eca772d1a5830336f84aca1d8198e5a3f4715cd1c7fc36d3cc7f7185091/msgpack-python-0.5.6.tar.gz (138kB)\n",
            "\u001b[K    100% |████████████████████████████████| 143kB 21.6MB/s \n",
            "\u001b[?25hCollecting msgpack-numpy==0.4.1 (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/43/393e30e2768b0357541ac95891f96b80ccc4d517e0dd2fa3042fc8926538/msgpack_numpy-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.9,>=0.8->thinc<6.11.0,>=6.10.1->spacy) (0.9.0)\n",
            "Building wheels for collected packages: spacy, murmurhash, cymem, preshed, thinc, pathlib, ujson, dill, regex, wrapt, cytoolz, msgpack-python\n",
            "  Running setup.py bdist_wheel for spacy ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/fb/00/28/75c85d5135e7d9a100639137d1847d41e914ed16c962d467e4\n",
            "  Running setup.py bdist_wheel for murmurhash ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/b8/94/a4/f69f8664cdc1098603df44771b7fec5fd1b3d8364cdd83f512\n",
            "  Running setup.py bdist_wheel for cymem ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/55/8d/4a/f6328252aa2aaec0b1cb906fd96a1566d77f0f67701071ad13\n",
            "  Running setup.py bdist_wheel for preshed ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/8f/85/06/2d132fb649a6bbcab22487e4147880a55b0dd0f4b18fdfd6b5\n",
            "  Running setup.py bdist_wheel for thinc ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d8/5c/3e/9acf5d9974fb1c9e7b467563ea5429c9325f67306e93147961\n",
            "  Running setup.py bdist_wheel for pathlib ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/f9/b2/4a/68efdfe5093638a9918bd1bb734af625526e849487200aa171\n",
            "  Running setup.py bdist_wheel for ujson ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
            "  Running setup.py bdist_wheel for dill ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/99/c4/ed/1b64d2d5809e60d5a3685530432f6159d6a9959739facb61f2\n",
            "  Running setup.py bdist_wheel for regex ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "  Running setup.py bdist_wheel for wrapt ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/48/5d/04/22361a593e70d23b1f7746d932802efe1f0e523376a74f321e\n",
            "  Running setup.py bdist_wheel for cytoolz ... \u001b[?25l-\b \b\\\b \b|\b \b/"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/f8/b1/86/c92e4d36b690208fff8471711b85eaa6bc6d19860a86199a09\n",
            "  Running setup.py bdist_wheel for msgpack-python ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d5/de/86/7fa56fda12511be47ea0808f3502bc879df4e63ab168ec0406\n",
            "Successfully built spacy murmurhash cymem preshed thinc pathlib ujson dill regex wrapt cytoolz msgpack-python\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: murmurhash, cymem, preshed, wrapt, cytoolz, plac, dill, pathlib, msgpack-python, msgpack-numpy, thinc, ujson, regex, spacy\n",
            "Successfully installed cymem-1.31.2 cytoolz-0.8.2 dill-0.2.7.1 msgpack-numpy-0.4.1 msgpack-python-0.5.6 murmurhash-0.28.0 pathlib-1.0.1 plac-0.9.6 preshed-1.0.0 regex-2017.4.5 spacy-2.0.11 thinc-6.10.2 ujson-1.35 wrapt-1.10.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ww7TG-FhhjSN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0bbd0ff-4cc2-445a-951b-b39f242813d8"
      },
      "cell_type": "code",
      "source": [
        "PATH='/content/drive/fastai/courses/dl1/data/nietzsche/'\n",
        "TRN_PATH = 'trn/'\n",
        "VAL_PATH = 'val/'\n",
        "TRN = f'{PATH}{TRN_PATH}'\n",
        "VAL = f'{PATH}{VAL_PATH}'\n",
        "\n",
        "%ls {PATH}"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nietzsche.txt  \u001b[0m\u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n48EfHwNhjSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "421cc8cd-9327-4c41-9afe-4b218f9ce90f"
      },
      "cell_type": "code",
      "source": [
        "%ls {PATH}trn"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nietzsche.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_igqTDWihjST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5dd095ae-47bd-4d17-8564-858c86dc6305"
      },
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(lower=True, tokenize=list)\n",
        "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
        "\n",
        "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
        "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
        "\n",
        "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1173, 57, 1, 601334)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "metadata": {
        "id": "oG4EOXjOhjSZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ]
    },
    {
      "metadata": {
        "id": "SzZH2CY6hjSZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulRnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs):\n",
        "        self.vocab_size = vocab_size\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Md2Cah81hjSb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulRnn(md.nt, n_fac, 512).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x4BkXGR3hjSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "82869005-1e46-4a87-d03d-4e5678825a19"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3111a6e0f3f14bc79fa1ef48f4034579",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.759435   1.761553  \n",
            " 14%|█▍        | 165/1173 [00:02<00:12, 78.43it/s, loss=1.73]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.586691   1.590428  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.509047   1.514635  \n",
            "    3      1.456913   1.46347   \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.46347])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {
        "id": "UjnENZxThjSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "5e5c2e05-6f6a-4549-88ff-4f8c29faee49"
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)\n",
        "\n",
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02537be62429434c876558f5d390a69d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.389399   1.418022  \n",
            " 14%|█▍        | 165/1173 [00:02<00:13, 75.12it/s, loss=1.42]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.385017   1.411296  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.382922   1.405069  \n",
            "    3      1.385784   1.40059   \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.40059])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "metadata": {
        "id": "YZdxcLRJhjSl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN loop"
      ]
    },
    {
      "metadata": {
        "id": "zHu2Usf_hjSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From the pytorch source\n",
        "\n",
        "def RNNCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
        "    return F.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b-ZfiY-phjSn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulRnn2(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNNCell(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
        "        outp = []\n",
        "        o = self.h\n",
        "        for c in cs: \n",
        "            o = self.rnn(self.e(c), o)\n",
        "            outp.append(o)\n",
        "        outp = self.l_out(torch.stack(outp))\n",
        "        self.h = repackage_var(o)\n",
        "        return F.log_softmax(outp, dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ft1vZYEohjSu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulRnn2(md.nt, n_fac, 512).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mebpfnjlhjSv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a4ffd971-2aec-467e-c424-0b9a1f0b7dde"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "584678a2e5cf4384ba9eb754ec5d6856",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.757587   1.750365  \n",
            " 10%|█         | 119/1173 [00:02<00:23, 44.11it/s, loss=1.75]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.585627   1.594013  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.509411   1.516172  \n",
            "    3      1.46629    1.469793  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.46979])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "metadata": {
        "id": "KjGp2fVfhjSz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ]
    },
    {
      "metadata": {
        "id": "nfmyRhAnhjSz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.GRU(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GtvAMgNchjS0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From the pytorch source code - for reference\n",
        "\n",
        "def GRUCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
        "    gi = F.linear(input, w_ih, b_ih)\n",
        "    gh = F.linear(hidden, w_hh, b_hh)\n",
        "    i_r, i_i, i_n = gi.chunk(3, 1)\n",
        "    h_r, h_i, h_n = gh.chunk(3, 1)\n",
        "\n",
        "    resetgate = F.sigmoid(i_r + h_r)\n",
        "    inputgate = F.sigmoid(i_i + h_i)\n",
        "    newgate = F.tanh(i_n + resetgate * h_n)\n",
        "    return newgate + inputgate * (hidden - newgate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VIAhlNkVhjS2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulGRU(md.nt, n_fac, 512).cuda()\n",
        "\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YlaEN0WbhjS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "6af003a3-ec1b-4d6f-a05b-cc4adf52a850"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 6, opt, F.nll_loss)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2b0d399230a40e0a04901f1294a2f20",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.634134   1.627754  \n",
            " 14%|█▍        | 163/1173 [00:02<00:13, 75.99it/s, loss=1.6] "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.469983   1.466235  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.400803   1.394144  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    3      1.344681   1.348228  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    4      1.32058    1.317386  \n",
            "    5      1.294916   1.298565  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.29856])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "metadata": {
        "id": "pdvyI6SRhjS7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2AdXVcKehjS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "974ebbf8-dce8-4226-e0b8-10542ccf7be4"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 3, opt, F.nll_loss)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "369ea7382b9243048b8e400d3a09c6a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.221177   1.249778  \n",
            " 14%|█▎        | 161/1173 [00:02<00:13, 74.96it/s, loss=1.26]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.219317   1.242545  \n",
            "    2      1.215105   1.237456  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.23746])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "metadata": {
        "id": "cg7CGE2ghjTA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Putting it all together: LSTM"
      ]
    },
    {
      "metadata": {
        "id": "T2JU5dqbhjTG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai import sgdr\n",
        "\n",
        "n_hidden=512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bf9QO5OVhjTH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
        "        super().__init__()\n",
        "        self.vocab_size,self.nl = vocab_size,nl\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs):\n",
        "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
        "                  V(torch.zeros(self.nl, bs, n_hidden)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ueuU9jQKhjTH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 2).cuda()\n",
        "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rQEorPgShjTI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.makedirs(f'{PATH}models', exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yp1Fz-vmhjTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "3ce0cd85-ff9b-4c97-981d-e74afbdcd450"
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 2, lo.opt, F.nll_loss)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d933e5076e4d4f9ba72fee6463356f71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.71842    1.65452   \n",
            " 10%|█         | 118/1173 [00:02<00:22, 46.16it/s, loss=1.72]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.62126    1.554723  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.55472])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "metadata": {
        "id": "LZ6E1UIShjTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "e5724837-3fba-4c35-ce40-901cabb843df"
      },
      "cell_type": "code",
      "source": [
        "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
        "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
        "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83d8c879b3fb4c1f97173719ce42522f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.45971    1.40309   \n",
            " 11%|█         | 126/1173 [00:05<00:49, 21.35it/s, loss=1.54]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.505412   1.44295   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.393366   1.346028  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    3      1.533939   1.461758  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    4      1.46138    1.403365  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    5      1.385364   1.331154  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    6      1.332018   1.290969  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    7      1.49764    1.44109   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    8      1.480651   1.429487  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    9      1.455378   1.39274   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    10     1.419714   1.36739   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    11     1.383215   1.326291  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    12     1.343279   1.290007  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    13     1.301592   1.257772  \n",
            "    14     1.274262   1.239197  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.2392])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "metadata": {
        "id": "fTSp1pyghjTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1176
        },
        "outputId": "21d615fb-2464-4e54-e952-d32801b0ac5d"
      },
      "cell_type": "code",
      "source": [
        "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
        "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
        "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3267c2e83624573a5ac241ecf5fd857",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=63), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.269279   1.23583   \n",
            " 10%|█         | 121/1173 [00:05<00:52, 20.20it/s, loss=1.29]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.270894   1.232607  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      1.263501   1.230537  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    3      1.270197   1.227512  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    4      1.266815   1.222202  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    5      1.258244   1.216917  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    6      1.251864   1.215179  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    7      1.253806   1.213527  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    8      1.250948   1.206551  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    9      1.24081    1.199701  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    10     1.238191   1.194188  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    11     1.237014   1.185697  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    12     1.225393   1.180643  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    13     1.218643   1.177651  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    14     1.223275   1.176257  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    15     1.223147   1.187298  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    16     1.216985   1.177259  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    17     1.214834   1.170124  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    18     1.206972   1.158012  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    19     1.200971   1.159187  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    20     1.19285    1.150551  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    21     1.187106   1.142975  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    22     1.185218   1.135279  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    23     1.1769     1.126153  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    24     1.166683   1.121345  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    25     1.172299   1.115435  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    26     1.15711    1.112466  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    27     1.160679   1.109233  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    28     1.157208   1.107021  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    29     1.159555   1.105417  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    30     1.155864   1.104763  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    31     1.157262   1.104553  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    32     1.169897   1.120725  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    33     1.165776   1.110071  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    34     1.163946   1.101645  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    35     1.152297   1.098993  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    36     1.151684   1.092831  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    37     1.143096   1.083514  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    38     1.138662   1.077749  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    39     1.125071   1.070114  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    40     1.124427   1.061139  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    41     1.115339   1.054876  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    42     1.110553   1.050491  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    43     1.10382    1.042245  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    44     1.099558   1.034943  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    45     1.096353   1.030048  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    46     1.091719   1.025344  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    47     1.089895   1.01981   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    48     1.077964   1.013741  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    49     1.081216   1.009158  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    50     1.070104   1.005288  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    51     1.072742   0.999782  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    52     1.067806   0.995923  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    53     1.068416   0.993266  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    54     1.060146   0.989768  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    55     1.058245   0.986993  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    56     1.05823    0.984664  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    57     1.046738   0.98184   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    58     1.050266   0.979607  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    59     1.050603   0.978361  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    60     1.047582   0.976811  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    61     1.049601   0.975943  \n",
            "    62     1.053668   0.975307  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.97531])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "metadata": {
        "id": "vEAKu4hUhjTO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJ1a4hxahjTP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test"
      ]
    },
    {
      "metadata": {
        "id": "_iOn1yDrhjTP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = TEXT.numericalize(inp)\n",
        "    p = m(VV(idxs.transpose(0,1)))\n",
        "    r = torch.multinomial(p[-1].exp(), 1)\n",
        "    return TEXT.vocab.itos[to_np(r)[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OAC3lB-jhjTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4175875f-d945-4afc-efbc-508e0b8ae5e4"
      },
      "cell_type": "code",
      "source": [
        "get_next('for thos')"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "metadata": {
        "id": "7ToPVwUxhjTR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next_n(inp, n):\n",
        "    res = inp\n",
        "    for i in range(n):\n",
        "        c = get_next(inp)\n",
        "        res += c\n",
        "        inp = inp[1:]+c\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L5gD6qlZhjTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8dd414de-8bc5-421c-9f7a-22814827a3fd"
      },
      "cell_type": "code",
      "source": [
        "print(get_next_n('for thos', 400))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for those time\\to what it science--words\\preferents2 suphose\\by the father, and\\necessity, and disposed\\and movement and double being life\\flood. here, men, ansiques deal away of religion\\as manifest sublime\\and which they was to\\sheen-man.--\"no\\hundred--date of democrity. we free more in\\desire conceale.\\\\i1 the trouble ats\\breaking nature sensible? and out others\\occasions: what is\\that is infredical, p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AKLFpNoShjTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}